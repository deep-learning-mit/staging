@article{Brown2020,
   abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
   author = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
   issn = {10495258},
   journal = {Advances in Neural Information Processing Systems},
   month = {5},
   publisher = {Neural information processing systems foundation},
   title = {Language Models are Few-Shot Learners},
   volume = {2020-December},
   url = {https://arxiv.org/abs/2005.14165v4},
   year = {2020},
}
@article{Soviany2022,
   abstract = {Training machine learning models in a meaningful order, from the easy samples to the hard ones, using curriculum learning can provide performance improvements over the standard training approach based on random data shuffling, without any additional computational costs. Curriculum learning strategies have been successfully employed in all areas of machine learning, in a wide range of tasks. However, the necessity of finding a way to rank the samples from easy to hard, as well as the right pacing function for introducing more difficult data can limit the usage of the curriculum approaches. In this survey, we show how these limits have been tackled in the literature, and we present different curriculum learning instantiations for various tasks in machine learning. We construct a multi-perspective taxonomy of curriculum learning approaches by hand, considering various classification criteria. We further build a hierarchical tree of curriculum learning methods using an agglomerative clustering algorithm, linking the discovered clusters with our taxonomy. At the end, we provide some interesting directions for future work.},
   author = {Petru Soviany and Radu Tudor Ionescu and Paolo Rota and Nicu Sebe},
   doi = {10.1007/S11263-022-01611-X/FIGURES/2},
   issn = {15731405},
   issue = {6},
   journal = {International Journal of Computer Vision},
   keywords = {Curriculum learning,Deep learning,Learning from easy to hard,Neural networks,Self-paced learning},
   month = {6},
   pages = {1526-1565},
   publisher = {Springer},
   title = {Curriculum Learning: A Survey},
   volume = {130},
   url = {https://link.springer.com/article/10.1007/s11263-022-01611-x},
   year = {2022},
}

@article{brunton2021modern,
  title={Modern Koopman theory for dynamical systems},
  author={Brunton, Steven L and Budi{\v{s}}i{\'c}, Marko and Kaiser, Eurika and Kutz, J Nathan},
  journal={arXiv preprint arXiv:2102.12086},
  year={2021}
}

@article{lusch2018deep,
  title={Deep learning for universal linear embeddings of nonlinear dynamics},
  author={Lusch, Bethany and Kutz, J Nathan and Brunton, Steven L},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={4950},
  year={2018},
  publisher={Nature Publishing Group UK London}
}

@misc{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj√∂rn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{yeung2019learning,
  title={Learning deep neural network representations for Koopman operators of nonlinear dynamical systems},
  author={Yeung, Enoch and Kundu, Soumya and Hodas, Nathan},
  booktitle={2019 American Control Conference (ACC)},
  pages={4832--4839},
  year={2019},
  organization={IEEE}
}

@article{abraham2019active,
  title={Active learning of dynamics for data-driven control using Koopman operators},
  author={Abraham, Ian and Murphey, Todd D},
  journal={IEEE Transactions on Robotics},
  volume={35},
  number={5},
  pages={1071--1083},
  year={2019},
  publisher={IEEE}
}

@inproceedings{han2020deep,
  title={Deep learning of Koopman representation for control},
  author={Han, Yiqiang and Hao, Wenjian and Vaidya, Umesh},
  booktitle={2020 59th IEEE Conference on Decision and Control (CDC)},
  pages={1890--1895},
  year={2020},
  organization={IEEE}
}

@article{ng2022learned,
  title={Learned Lifted Linearization Applied to Unstable Dynamic Systems Enabled by Koopman Direct Encoding},
  author={Ng, Jerry and Asada, H Harry},
  journal={IEEE Control Systems Letters},
  volume={7},
  pages={1153--1158},
  year={2022},
  publisher={IEEE}
}

@article{Shi2022,
   abstract = {Recently Koopman operator has become a promising data-driven tool to facilitate real-time control for unknown nonlinear systems. It maps nonlinear systems into equivalent linear systems in embedding space, ready for real-time linear control methods. However, designing an appropriate Koopman embedding function remains a challenging task. Furthermore, most Koopman-based algorithms only consider nonlinear systems with linear control input, resulting in lousy prediction and control performance when the system is fully nonlinear with the control input. In this work, we propose an end-to-end deep learning framework to learn the Koopman embedding function and Koopman Operator together to alleviate such difficulties. We first parameterize the embedding function and Koopman Operator with the neural network and train them end-to-end with the K-steps loss function. Then, an auxiliary control network is augmented to encode the nonlinear state-dependent control term to model the nonlinearity in the control input. This encoded term is considered the new control variable instead to ensure linearity of the modeled system in the embedding system. We next deploy Linear Quadratic Regulator (LQR) on the linear embedding space to derive the optimal control policy and decode the actual control input from the control net. Experimental results demonstrate that our approach outperforms other existing methods, reducing the prediction error by order of magnitude and achieving superior control performance in several nonlinear dynamic systems like damping pendulum, CartPole, and the seven DOF robotic manipulator.},
   author = {Haojie Shi and Max Q.H. Meng},
   doi = {10.1109/LRA.2022.3184036},
   issn = {23773766},
   issue = {3},
   journal = {IEEE Robotics and Automation Letters},
   keywords = {Deep learning methods,Machine learning for robot control,Model learning for control},
   month = {7},
   pages = {7700-7707},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Deep Koopman Operator With Control for Nonlinear Systems},
   volume = {7},
   year = {2022},}

@article{Shi2022,
   abstract = {Recently Koopman operator has become a promising data-driven tool to facilitate real-time control for unknown nonlinear systems. It maps nonlinear systems into equivalent linear systems in embedding space, ready for real-time linear control methods. However, designing an appropriate Koopman embedding function remains a challenging task. Furthermore, most Koopman-based algorithms only consider nonlinear systems with linear control input, resulting in lousy prediction and control performance when the system is fully nonlinear with the control input. In this work, we propose an end-to-end deep learning framework to learn the Koopman embedding function and Koopman Operator together to alleviate such difficulties. We first parameterize the embedding function and Koopman Operator with the neural network and train them end-to-end with the K-steps loss function. Then, an auxiliary control network is augmented to encode the nonlinear state-dependent control term to model the nonlinearity in the control input. This encoded term is considered the new control variable instead to ensure linearity of the modeled system in the embedding system. We next deploy Linear Quadratic Regulator (LQR) on the linear embedding space to derive the optimal control policy and decode the actual control input from the control net. Experimental results demonstrate that our approach outperforms other existing methods, reducing the prediction error by order of magnitude and achieving superior control performance in several nonlinear dynamic systems like damping pendulum, CartPole, and the seven DOF robotic manipulator.},
   author = {Haojie Shi and Max Q.H. Meng},
   doi = {10.1109/LRA.2022.3184036},
   issn = {23773766},
   issue = {3},
   journal = {IEEE Robotics and Automation Letters},
   keywords = {Deep learning methods,Machine learning for robot control,Model learning for control},
   month = {7},
   pages = {7700-7707},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Deep Koopman Operator With Control for Nonlinear Systems},
   volume = {7},
   year = {2022},
}
@article{Bakker:KoopHybrid,
   abstract = {The Koopman operator lifts nonlinear dynamical systems into a functional space of observables, where the dynamics are linear. In this paper, we provide three different Koopman representations for hybrid systems. The first is specific to switched systems, and the second and third preserve the original hybrid dynamics while eliminating the discrete state variables; the second approach is straightforward, and we provide conditions under which the transformation associated with the third holds. Eliminating discrete state variables provides computational benefits when using data-driven methods to learn the Koopman operator and its observables. Following this, we use deep learning to implement each representation on two test cases, discuss the challenges associated with those implementations, and propose areas of future work.},
   author = {Craig Bakker and Arnab Bhattacharya and Samrat Chatterjee and Casey J. Perkins and Matthew R. Oster},
   month = {6},
   title = {Learning Koopman Representations for Hybrid Systems},
   url = {http://arxiv.org/abs/2006.12427},
   year = {2020},
}
@ARTICLE{NgCable,
  author={Ng, Jerry and Asada, H. Harry},
  journal={IEEE Robotics and Automation Letters}, 
  title={Model Predictive Control and Transfer Learning of Hybrid Systems Using Lifting Linearization Applied to Cable Suspension Systems}, 
  year={2022},
  volume={7},
  number={2},
  pages={682-689},
  doi={10.1109/LRA.2021.3131750}}
@inproceedings{Govindarajan:KoopHyPend,
   abstract = {We apply an operator-theoretic viewpoint to a class of non-smooth dynamical systems that are exposed to event-triggered state resets. The considered benchmark problem is that of a pendulum which receives a downward kick at certain fixed angles. The pendulum is modeled as a hybrid automaton and is analyzed from both a geometric perspective and the formalism of Koopman operator theory. A connection is drawn between these two interpretations of a dynamical system by establishing a link between the spectral properties of the Koopman operator and the geometric properties in the state-space.},
   author = {Nithin Govindarajan and Hassan Arbabi and Louis Van Blargian and Timothy Matchen and Emma Tegling and Igor Mezic},
   doi = {10.1109/CDC.2016.7799266},
   isbn = {9781509018376},
   journal = {2016 IEEE 55th Conference on Decision and Control, CDC 2016},
   month = {12},
   pages = {6477-6484},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {An operator-theoretic viewpoint to non-smooth dynamical systems: Koopman analysis of a hybrid pendulum},
   year = {2016},
}
@article{Mamakoukas2023Stable,
   abstract = {In this article, we demonstrate the benefits of imposing stability on data-driven Koopman operators. The data-driven identification of stable Koopman operators (DISKO) is implemented using an algorithm&#x00A0;[1] that computes the nearest <italic>stable</italic> matrix solution to a least-squares reconstruction error. As a first result, we derive a formula that describes the prediction error of Koopman representations for an arbitrary number of time steps, and which shows that stability constraints can improve the predictive accuracy over long horizons. As a second result, we determine formal conditions on basis functions of Koopman operators needed to satisfy the stability properties of an underlying nonlinear system. As a third result, we derive formal conditions for constructing Lyapunov functions for nonlinear systems out of stable data-driven Koopman operators, which we use to verify stabilizing control from data. Finally, we demonstrate the benefits of DISKO in prediction and control with simulations using a pendulum and a quadrotor and experiments with a pusher-slider system. The paper is complemented with a video: <uri>https://sites.google.com/view/learning-stable-koopman</uri>.},
   author = {Giorgos Mamakoukas and Ian Abraham and Todd D. Murphey},
   doi = {10.1109/TRO.2022.3228130},
   issn = {19410468},
   journal = {IEEE Transactions on Robotics},
   keywords = {Analytical models,Control Lyapunov functions,Koopman operator,Mathematical models,Nonlinear dynamical systems,Numerical stability,Predictive models,Robots,Stability analysis,data-driven control,stability},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Learning Stable Models for Prediction and Control},
   year = {2023},
}
@article{Tsipras2020,
   abstract = {Building rich machine learning datasets in a scal-able manner often necessitates a crowd-sourced data collection pipeline. In this work, we use human studies to investigate the consequences of employing such a pipeline, focusing on the popular ImageNet dataset. We study how specific design choices in the ImageNet creation process impact the fidelity of the resulting dataset-including the introduction of biases that state-of-the-art models exploit. Our analysis pinpoints how a noisy data collection pipeline can lead to a systematic mis-alignment between the resulting benchmark and the real-world task it serves as a proxy for. Finally, our findings emphasize the need to augment our current model training and evaluation toolkit to take such misalignments into account. 1},
   author = {Dimitris Tsipras and Shibani Santurkar and Logan Engstrom and Andrew Ilyas and Aleksander M Àõ Adry},
   title = {From ImageNet to Image Classification: Contextualizing Progress on Benchmarks},
   year = {2020},
}
@misc{Rawlings2022,
   author = {James B Rawlings and David Q Mayne and Moritz M Diehl and Santa Barbara},
   isbn = {2020942771},
   title = {Model Predictive Control: Theory, Computation, and Design 2nd Edition},
   url = {http://www.nobhillpublishing.com},
   year = {2022},
}

@article{Lusch2018,
   abstract = {Identifying coordinate transformations that make strongly nonlinear dynamics approximately linear has the potential to enable nonlinear prediction, estimation, and control using linear theory. The Koopman operator is a leading data-driven embedding, and its eigenfunctions provide intrinsic coordinates that globally linearize the dynamics. However, identifying and representing these eigenfunctions has proven challenging. This work leverages deep learning to discover representations of Koopman eigenfunctions from data. Our network is parsimonious and interpretable by construction, embedding the dynamics on a low-dimensional manifold. We identify nonlinear coordinates on which the dynamics are globally linear using a modified auto-encoder. We also generalize Koopman representations to include a ubiquitous class of systems with continuous spectra. Our framework parametrizes the continuous frequency using an auxiliary network, enabling a compact and efficient embedding, while connecting our models to decades of asymptotics. Thus, we benefit from the power of deep learning, while retaining the physical interpretability of Koopman embeddings. It is often advantageous to transform a strongly nonlinear system into a linear one in order to simplify its analysis for prediction and control. Here the authors combine dynamical systems with deep learning to identify these hard-to-find transformations.},
   author = {Bethany Lusch and J. Nathan Kutz and Steven L. Brunton},
   doi = {10.1038/s41467-018-07210-0},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications 2018 9:1},
   keywords = {Applied mathematics,Nonlinear phenomena},
   month = {11},
   pages = {1-10},
   pmid = {30470743},
   publisher = {Nature Publishing Group},
   title = {Deep learning for universal linear embeddings of nonlinear dynamics},
   volume = {9},
   url = {https://www.nature.com/articles/s41467-018-07210-0},
   year = {2018},
}

@article{Koopmanism,
   abstract = {A majority of methods from dynamical system analysis, especially those applied settings, rely on Poincar√©'s geometric picture that focuses on "dynamics of states." While this picture has fueled our field for a century, it has shown difficulties handling high-dimensional, ill-described, and uncertasystems, which are more and more common engineered systems design and analysis of "big data" measurements. This overview article presents an alternative framework for dynamical systems, based on the "dynamics of observables" picture. The central object is the Koopman operator: an infinite-dimensional, linear operator that is nonetheless capable of capturing the full nonlinear dynamics. The first goal of this paper is to make it clear how methods that appeared different papers and contexts all relate to each other through spectral properties of the Koopman operator. The second goal is to present these methods a concise manner an effort to make the framework accessible to researchers who would like to apply them, but also, expand and improve them. Finally, we aim to provide a road map through the literature where each of the topics was described detail. We describe three maconcepts: Koopman mode analysis, Koopman eigenquotients, and continuous indicators of ergodicity. For each concept, we provide a summary of theoretical concepts required to define and study them, numerical methods that have been developed for their analysis, and, when possible, applications that made use of them. The Koopman framework is showing potential for crossing over from academic and theoretical use to industrial practice. Therefore, the paper highlights its strengths applied and numerical contexts. Additionally, we point out areas where an additional research push is needed before the approach is adopted as an off-the-shelf framework for analysis and design. ¬© 2012 American Institute of Physics.},
   author = {Marko Budi≈°iƒá and Ryan Mohr and Igor Meziƒá},
   doi = {10.1063/1.4772195},
   issn = {10541500},
   issue = {4},
   journal = {Chaos},
   month = {10},
   publisher = {American Institute of Physics Inc.},
   title = {Applied Koopmanism},
   volume = {22},
   year = {2012},
}
@misc{AsadaDE,
   abstract = {The complexity of robot dynamics often pertains to the hybrid nature of dynamics, where governing dynamic equations consist of heterogenous equations that are switched depending on the state of the system. Legged robots and manipulator robots experience contact-noncontact discrete transitions, causing switching of governing equations. Analysis of these robot systems have been a challenge due to the lack of a global, unified model that is amenable to analysis of the global behaviors. Composition operator theory has the potential to provide a global, unified representation of those heterogenous dynamical systems. It is expected that, if the theory is applicable, those fundamentally challenging robotics systems can be treated as linear dynamical systems in a lifted space. The current work addresses under which conditions a unified linear representation exists in a global sense for a class of heterogenous dynamical systems and how the theory can be applied to those robotics problems. First, a kernel representation of composition operators is obtained, and conditions required for converting the kernel representation to a linear state transition equation are established. This analysis results in an algorithm to convert a class of heterogenous systems including hybrid and switched systems directly to a global, unified linear model. Unlike prevalent data-driven methods and Dynamic Mode Decomposition, where results can vary depending on numerical data, the proposed method does not require numerical simulation of the original dynamics. The implication of the new method and its impact upon robotics are discussed. A few examples validate and demonstrate the method.},
   author = {H Harry Asada},
   keywords = {Hybrid system,Index Terms-Composition operator,Koopman operator,Lifting linearization,Robot dynamics},
   title = {Global, Unified Representation of Heterogenous Robot Dynamics Using Composition Operators},
   url = {http://ieeexplore.ieee.org},
}