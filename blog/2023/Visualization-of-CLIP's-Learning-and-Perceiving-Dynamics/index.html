<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Alive Scene | 6.S898 Deep Learning Blogs 2023</title> <meta name="author" content="abc b c"/> <meta name="description" content="Inspired by the captivating Enchanted Portraits of the Harry Potter universe, my project unveils an innovative AI pipeline that transcends traditional scene-capture methods. Rather than merely recording scenes as a sequence of static images, this pipeline is intricately designed to interpret and articulate the dynamic behavior of various elements within a scene by utilizing CLIP semantic embeddings. This nuanced understanding enables the scenes to evolve autonomously and organically, mirroring the fluidity and spontaneity of living entities."/> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/staging/assets/css/main.css"> <link rel="canonical" href="https://deep-learning-mit.github.io/staging/blog/2023/Visualization-of-CLIP's-Learning-and-Perceiving-Dynamics/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/staging/assets/js/theme.js"></script> <script src="/staging/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/staging/assets/js/distillpub/template.v2.js"></script> <script src="/staging/assets/js/distillpub/transforms.v2.js"></script> <script src="/staging/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p,.fake-img figcaption{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Alive Scene",
      "description": "Inspired by the captivating Enchanted Portraits of the Harry Potter universe, my project unveils an innovative AI pipeline that transcends traditional scene-capture methods. Rather than merely recording scenes as a sequence of static images, this pipeline is intricately designed to interpret and articulate the dynamic behavior of various elements within a scene by utilizing CLIP semantic embeddings. This nuanced understanding enables the scenes to evolve autonomously and organically, mirroring the fluidity and spontaneity of living entities.",
      "published": "December 9, 2023",
      "authors": [
        {
          "author": "Chi-Li Cheng",
          "authorURL": "https://chilicheng.com",
          "affiliations": [
            {
              "name": "Massachusetts Institute of Technology",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/staging/">6.S898 Deep Learning Blogs 2023</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/staging/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Alive Scene</h1> <p>Inspired by the captivating Enchanted Portraits of the Harry Potter universe, my project unveils an innovative AI pipeline that transcends traditional scene-capture methods. Rather than merely recording scenes as a sequence of static images, this pipeline is intricately designed to interpret and articulate the dynamic behavior of various elements within a scene by utilizing CLIP semantic embeddings. This nuanced understanding enables the scenes to evolve autonomously and organically, mirroring the fluidity and spontaneity of living entities.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#project-proposal">Project Proposal</a></div> <ul> <li><a href="#abstract">Abstract</a></li> <li><a href="#introduction">Introduction</a></li> <li><a href="#methodology">Methodology</a></li> <li><a href="#potential-contributions">Potential Contributions</a></li> </ul> </nav> </d-contents> <h2 id="enchanting-images-with-semantic-embedding">Enchanting Images with Semantic Embedding</h2> <p>“Alive Scene” is an advanced AI-driven project that revolutionizes the concept of scene capture, drawing inspiration from the enchanting, ever-changing portraits in the Harry Potter series. This innovative pipeline goes beyond traditional methods of capturing scenes as static images. Instead, it delves deep into the semantic understanding of each scene, enabling it to not only recreate these scenes with high fidelity but also to imbue them with the ability to act, evolve, and respond autonomously.</p> <p>The following GIF image on the right is the output from the Alive Scene Pipeline. Notice that these scenes start from the same status.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/7cFU.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/7cFU.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/7cFU.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/7cFU.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Hogwarts Portraits </div> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/allt5.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/allt5.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/allt5.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/allt5.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Alive Scene captures cats' napping behaviors </div> </figure> </div> </div> <p>The core of this project lies in its sophisticated AI algorithms that analyze and interpret the nuances of each scene, from the physical elements to the underlying emotions and narratives. This enables the system to generate dynamic, lifelike representations that are far from static images. These AI-crafted scenes possess the unique ability to change organically over time, reflecting the natural progression and evolution one would expect in real life.</p> <p>Through “Alive Scene,” portraits and scenes are no longer mere representations; they become entities with a semblance of life, capable of exhibiting behaviors and changes that mirror the fluidity and spontaneity of living beings. There are three elements in this project, the first is using CLIP model as encoder to compress image into clip embeddings. Second, train a generator to reconstruct the original image from the CLIP embedding. then train a behavior model to lean the behavior of clip embeddings in the clip feature space; the behavior will use to drive the generator; making the scene representation alive. The following is the diagrams of the pipeline.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/pipeline-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/pipeline-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/pipeline-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/pipeline.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Alive Scene Pipeline </div> </figure> </div> <h3 id="introduction">Introduction</h3> <p>The CLIP (Contrastive Language–Image Pre-training) model<d-cite key="radford2021learning"></d-cite>, represents a groundbreaking approach in integrating visual and textual data within the realm of artificial intelligence. In this project, it plays and important role to comprehend the scenario and characters’ behaviors in the scene. Detailed investigations<d-cite key="wang2020understanding"></d-cite> <d-cite key="shi2023understanding"></d-cite> <d-cite key="zhao2017exact"></d-cite> offers insightful understanding of the model’s operations, showing the potential that CLIP embeddings could make a machine comprehend and compress complex information of images.</p> <p>The study<d-cite key="author2021cinn"></d-cite> explores using conditional Invertible Neural Networks (cINNs) for transforming still images into videos, highlighting cINNs’ prowess in handling static to dynamic content transitions. Although proficient in capturing motion, the model’s grasp on object/event types may benefit from CLIP embeddings enhancement. My project, unlike this work, aims to animate static scene representations with self-driven behaviors, not just manipulate videos.</p> <p>Another significant work, “Make-A-Video”<d-cite key="singer2022makeavideo"></d-cite>, introduces a text-to-video generation method utilizing text-to-image models. This approach circumvents the need for text-video paired data, learning from text-image data and unsupervised videos. It employs a spatiotemporal diffusion model and super-resolution techniques for high-quality video creation from text. My project differs, focusing on bringing life to existing videos or image sequences, rather than generating new content from text.</p> <p>Despite the static background, the cats’ movements are so subtle that they pose a challenge for human observers to distinguish differences between frames. To visualize the clip embeddings of the frames from the video, I employ both UMAP and t-SNE<d-cite key="maaten2008tsne"></d-cite> techniques for gaining more insights.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/latent_umap.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/latent_umap.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/latent_umap.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/latent_umap.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> UMAP Visualization </div> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/latent_tsne.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/latent_tsne.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/latent_tsne.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/latent_tsne.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> t-SNE Visualization </div> </figure> </div> <p>The behavior over time resembles a ‘spaghetti’ pattern, indicating that certain scenarios or behaviors may recur (as seen in the crossings or interactions within the spaghetti diagram). Some intersecting points demonstrate similar tendencies, while others are more unpredictable, highlighting the complexity of the video.</p> <p>Both visualizations provide a promising sign: the end and start frames are positioned close to those in the middle. This proximity allows the Alive Scene to operate seamlessly and endlessly. For example, when the Alive Scene approaches a point near the end, it can smoothly transition to a frame somewhere in the middle. Similarly, when it encounters a region where different frames cluster together, it has a variety of options to choose from for its next move. This flexibility is key to making the Alive Scene function effectively.</p> <h3 id="generator">Generator</h3> <p>The Generator (decoder) is a SIREN model, which employs CLIP semantic embeddings and positional embeddings of pixel coordinates to generate RGB colors<d-cite key="sitzmann2019siren"></d-cite>. SIRENs, or Sinusoidal Representation Networks, diverge from traditional neural networks by utilizing sinusoidal activation functions instead of common ones like ReLU. These networks are adept at implicitly representing intricate data patterns, making them particularly advantageous for tasks that involve complex spatial structures or continuous data. The incorporation of periodic activation functions in SIRENs can significantly enhance deep learning capabilities, especially in fields such as computer vision and generative models.</p> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/SIREN_DECODER-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/SIREN_DECODER-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/SIREN_DECODER-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/SIREN_DECODER.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> a SIREN model as the generator </div> </figure> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/tp_siren.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/tp_siren.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/tp_siren.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/tp_siren.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> the training progression </div> </figure> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/generated_.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/generated_.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/generated_.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/generated_.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Original Video vs Generated Video </div> </figure> <p>The code of the generator model (SIREN)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SineLayer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">w0</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">SineLayer</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">w0</span> <span class="o">=</span> <span class="n">w0</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">w0</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Siren</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">w0</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="mi">560</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Siren</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="nc">SineLayer</span><span class="p">(</span><span class="n">w0</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="nc">SineLayer</span><span class="p">(</span><span class="n">w0</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="nc">SineLayer</span><span class="p">(</span><span class="n">w0</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="nc">SineLayer</span><span class="p">(</span><span class="n">w0</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">))</span>

        <span class="c1"># Init weights
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">self</span><span class="p">.</span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">weight</span><span class="p">.</span><span class="nf">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">in_dim</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">in_dim</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">weight</span><span class="p">.</span><span class="nf">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="n">hidden_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">w0</span><span class="p">,</span>
                                        <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="n">hidden_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">w0</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">net</span><span class="p">[</span><span class="mi">4</span><span class="p">].</span><span class="n">weight</span><span class="p">.</span><span class="nf">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="n">hidden_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">w0</span><span class="p">,</span>
                                        <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="n">hidden_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">w0</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">net</span><span class="p">[</span><span class="mi">6</span><span class="p">].</span><span class="n">weight</span><span class="p">.</span><span class="nf">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="n">hidden_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">w0</span><span class="p">,</span>
                                        <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="n">hidden_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">w0</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">net</span><span class="p">[</span><span class="mi">8</span><span class="p">].</span><span class="n">weight</span><span class="p">.</span><span class="nf">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="n">hidden_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">w0</span><span class="p">,</span>
                                        <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="n">hidden_dim</span><span class="p">)</span> <span class="o">/</span> <span class="n">w0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_optimizer</span><span class="p">,</span> <span class="n">nb_epochs</span><span class="o">=</span><span class="mi">15000</span><span class="p">):</span>
    <span class="n">psnr</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">nb_epochs</span><span class="p">)):</span>
        <span class="n">model_output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">pixel_coordinates</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">model_output</span> <span class="o">-</span> <span class="n">pixel_values</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
        <span class="n">psnr</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="mi">20</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">log10</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())))</span>

        <span class="n">model_optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">model_optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">psnr</span><span class="p">,</span> <span class="n">model_output</span>
</code></pre></div></div> <h3 id="behavior-model">Behavior model</h3> <p>This project introduces a customized asymmetrical Variational Autoencoder (VAE)<d-cite key="kingma2014autoencoding"></d-cite> as the probabilistic model to predict motion within the CLIP embedding space. A VAE-like model may prove beneficial for this task for two primary reasons. Firstly, they are adept at learning a continuous, smooth latent space, facilitating efficient interpolation and manipulation of data representations. Given that the training data derives from a video, it is inherently sequential and should be represented in a continuous fashion. Secondly, VAEs utilize amortized inference, where the encoder is trained to generalize the mapping of inputs to the latent space across the dataset, as opposed to conducting inference anew for each input. For this project, the objective is to devise a method that allows for a smooth navigation within the observed embedding space.</p> <p>The code of the behavior model (VAE)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># BehaviorModel(inspired by VAE)
</span><span class="k">class</span> <span class="nc">BehaviorModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">VAE</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="c1"># Encoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="mi">400</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc21</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>  <span class="c1"># Mean
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc22</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>  <span class="c1"># Log variance
</span>        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.55</span><span class="p">)</span>

        <span class="c1"># Decoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="mi">400</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc5</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h1</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">bn1</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">h2</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">bn2</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc2</span><span class="p">(</span><span class="n">h1</span><span class="p">)))</span>
        <span class="n">h2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">h2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc21</span><span class="p">(</span><span class="n">h2</span><span class="p">),</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc22</span><span class="p">(</span><span class="n">h2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reparameterize</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">h3</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">bn3</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc3</span><span class="p">(</span><span class="n">z</span><span class="p">)))</span>
        <span class="n">h4</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">bn4</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc4</span><span class="p">(</span><span class="n">h3</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc5</span><span class="p">(</span><span class="n">h4</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>

<span class="c1"># Loss function
</span><span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
    <span class="n">BCE</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="p">.</span><span class="nf">exp</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">BCE</span> <span class="o">+</span> <span class="n">KLD</span>

<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
    <span class="c1"># Use Mean Squared Error for the reconstruction loss
</span>    <span class="n">MSE</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># KLD is unchanged
</span>    <span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="p">.</span><span class="nf">exp</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">MSE</span> <span class="o">+</span> <span class="n">KLD</span>
</code></pre></div></div> <p>The process begins with a CLIP embedding as the input, which is then transformed by the model to output a motion vector. This vector retains the same dimensions as the CLIP embedding and is utilized to alter the original embedding, facilitating the generation of the subsequent frame based on this modified embedding.</p> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/PrbabilisticModel-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/PrbabilisticModel-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/PrbabilisticModel-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/PrbabilisticModel.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> the Asymmetrical VAE </div> </figure> <p>In this case, I generate 200 frames for training; the number is quite small. To enhance the model’s learning efficacy, new data points are generated through linear interpolation between existing data points (frames). By doing this, I generated 1000 clip embeddings and frames. These newly created samples undergo normalization to conform to the geometric constraints of the CLIP embedding space, often characterized as a hypersphere. This normalization process ensures that the interpolated data points adhere to the distribution pattern of the original embeddings. As depicted in the diagram, this technique leads to a densified clustering of data points in close proximity to the original embeddings, which is advantageous. It implies a higher confidence in the authenticity of these new points due to their closeness to the authentic, or ground truth, data.</p> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/Interpolation-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/Interpolation-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/Interpolation-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/Interpolation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Gaining more data points by Interpolation </div> </figure> <p>When operating the process that animates the Alive Scene, it occasionally generates artifacts. This may be caused by certain movements that deviate significantly from the observed reality. Please refer to the following GIF for an example.</p> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/broken.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/broken.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/broken.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/broken.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Artifacts </div> </figure> <p>To resolve the issue, I have developed a post-processing technique that stabilizes the outcomes. The process begins by re-normalizing the resulting embedding onto the hypersphere. Following this, a weighted parameter is introduced to draw the vector incrementally toward the domain of previously observed CLIP embeddings. For example, if the weighting parameter is set to 0.1 for the observed embedding, it would be scaled by 0.1, while the predicted embedding is scaled by 0.9. These two are then summed to produce a final embedding that, while primarily influenced by the prediction, retains a subtle alignment with the observed data. This weighted approach aims to mitigate artifacts by anchoring the predictions within the realm of observed realities.</p> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/Post-curing-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/Post-curing-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/Post-curing-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/Post-curing.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Post-curing method </div> </figure> <p>By applying this method, the Alive Scene has started to yield more stable results. Interestingly, the outcomes are varied, exhibiting behaviors akin to a living creature — somewhat unpredictable yet within a framework of predictability.</p> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/allt5.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/allt5.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/allt5.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/allt5.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> 4 different versions </div> </figure> <h3 id="manipulation">Manipulation</h3> <p>The Alive Scene operates autonomously, and to explore the modulation of its behavior, I have introduced the concept of ‘temperature.’ This concept acts as a coefficient that scales the movement vector, thereby allowing the scene to exhibit behaviors that are either more expansive and varied, or more constrained and subtle, depending on the temperature setting.</p> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/TEMPERATURE-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/TEMPERATURE-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/TEMPERATURE-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/TEMPERATURE.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> 4 different versions </div> </figure> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/vt.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/vt.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/vt.gif-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/vt.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> different temperature settings </div> </figure> <h3 id="conclusion">Conclusion</h3> <p>The “Alive Scene” project signifies a profound achievement in the domain of Deep Learning for scene representation. It leverages CLIP semantic embeddings to decode and imbue scenes with lifelike attributes, while also seamlessly integrating the potent SIREN model as a generator, capable of breathing vitality into the processed embeddings by producing authentic images.</p> <p>Furthermore, the project implements an asymmetric Variational Autoencoder (VAE) to predict and model motion within the CLIP embedding space, thereby enhancing the dynamism and fluidity of the scenes.</p> <p>However, the significance of this undertaking extends well beyond its technical accomplishments. By giving birth to scenes that autonomously and organically evolve, the project ushers in a transformative era of possibilities in digital storytelling and interactive media, fundamentally reshaping the landscape of creative expression in the digital realm.</p> <h3 id="future-work">Future Work</h3> <p>In this project, a SIREN model is trained to create a 2D scene representation. This model can be extended to generate a 3D scene by simply adding an additional output node to adopt the Neural Radiance Field (NeRF)<d-cite key="mildenhall2020nerf"></d-cite> architecture. Such an enhancement allows the 3D Alive Scene to offer a more immersive and complex scene representation. Looking ahead, it’s conceivable that a non-player character (NPC) could be manipulated in this manner, especially if the model, when trained on a vast dataset, can learn more sophisticated behaviors. This approach has the potential to encapsulate all necessary information within a highly compact model, offering an extremely lightweight solution for dynamic scene generation.</p> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/2dvs3d-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/2dvs3d-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/2dvs3d-1400.webp"/> <img src="/staging/assets/img/2023-12-09-Alive%20Scene%20Enchanting%20images%20with%20Semantic%20Embedding/2dvs3d.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> extend the model for a 3D Scene </div> </figure> <h3 id="potential-usages-and-contributions">Potential Usages and Contributions:</h3> <p>Digital Art and Entertainment: This project can revolutionize digital art and entertainment by offering dynamic, evolving scenes that enhance animations and virtual experiences.</p> <p>Film and Animation: It can automate the generation of realistic backgrounds, streamlining the production process for films and animated content.</p> <p>Advertising and Marketing: The project offers the capability to create interactive, dynamic advertising content, thereby engaging audiences more effectively.</p> <p>Behavioral Studies: It provides a tool for in-depth analysis of human and animal behaviors, supporting research in fields such as psychology, ethology, and anthropology.</p> <p>Cultural Preservation: This technology can enliven historical scenes or artworks in museums, offering visitors more immersive and engaging experiences.</p> <p>Data Visualization: It introduces innovative methods for interacting with and interpreting complex data, useful in sectors like finance and healthcare.</p> <p>Gaming: The project enables the creation of NPCs with realistic behaviors, significantly enhancing the gaming experience.</p> <p>Architecture and Engineering: It can be applied for dynamic visualizations in architectural and engineering projects, aiding in design and planning.</p> <p>Conservation: This technology can contribute to wildlife conservation by facilitating the study of animal behaviors in natural settings.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/staging/assets/bibliography/2023-12-09-Alive-Scene.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2023" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>